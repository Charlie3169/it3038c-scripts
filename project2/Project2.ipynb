{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "\n",
    "This project is meant to be the start of my own collection of webscraping functionalities.\n",
    "Currently I have created a function that randomly traverses the web by grabbing links on webpages and visiting them.\n",
    "\n",
    "I would eventually want to do a bunch of stuff with text analysis, word cloud generation, web sockets, and other networking functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import socket\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoup(url):\n",
    "    r = requests.get(url).content    \n",
    "    return BeautifulSoup(r, 'html.parser')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSoup(soup):\n",
    "    print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllText(soup):\n",
    "    text = soup.get_text()    \n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in progress\n",
    "def getWordCloud(soup):\n",
    "    words = {}        \n",
    "    for link in soup.find_all():\n",
    "       print(\"\")\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in progress\n",
    "def getSiteIP(url):\n",
    "    try:\n",
    "        ip = socket.gethostbyname(url)\n",
    "        return ip\n",
    "    except:\n",
    "        return \"192.168.1.1\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSiteLocation(ip):\n",
    "    \n",
    "    ipInfo = requests.get(f\"https://ipinfo.io/{ip}/geo\").json()\n",
    "\n",
    "    try:        \n",
    "        print(f\"Location: {ipInfo['loc']}\")        \n",
    "    except:\n",
    "        print(\"Ipinfo.io failed to return location data for this address\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextByElement(soup, tag, attrs):\n",
    "    outputList = []\n",
    "    for element in soup.find_all(tag, attrs):\n",
    "        outputList.append(element.text)\n",
    "    return outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllLinks(soup):\n",
    "    outputList = []\n",
    "    for link in soup.find_all('a', attrs={'href':re.compile(\"^http\")}):\n",
    "        outputList.append(link.get('href'))\n",
    "    return outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverseWeb(startingLink, visitedLinks):\n",
    "    print(f\"Current Link: {startingLink}\")\n",
    "    visitedLinks.add(startingLink)\n",
    "    links = getAllLinks(getSoup(startingLink))    \n",
    "    \n",
    "    if(len(links) > 0):        \n",
    "        print(f\"Branches points from here: {len(links)}\")\n",
    "        nextLink = links[random.randint(0, len(links) - 1)]   \n",
    "        \n",
    "        # This part could be improved on\n",
    "        while(nextLink in visitedLinks):\n",
    "            nextLink = links[random.randint(0, len(links) - 1)]   \n",
    "                     \n",
    "        traverseWeb(nextLink, visitedLinks)  \n",
    "    else:\n",
    "        print(\"\\nLink chain ended\")\n",
    "        print(f\"Total links visited: {len(visitedLinks)}\")\n",
    "        print(f\"Links visited: {visitedLinks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip to main content\n",
      "IT3038C\n",
      "Syllabus\n",
      "Modules\n",
      "GitHub\n",
      "Module 1 – Getting Started with your VMs\n",
      "Module 2 – Bash\n",
      "Module 3 – PowerShell\n",
      "Module 4 – Git and GitHub\n",
      "Module 5 – Python\n",
      "Module 6 – Node JS\n",
      "Module 7 - Modules, Plugins, Debugging\n",
      "Module 8 – Data Types & RegEx\n",
      "Module 9 – Web Scraping\n",
      "Module 10 – Working with APIs\n",
      "Module 11 – Heroku\n",
      "Module 12 – Websites in Python using Flask\n",
      "WIP\n",
      "\n",
      "https://www.debuggex.com/cheatsheet/regex/python\n",
      "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "http://www.pythonforbeginners.com/beautifulsoup/beautifulsoup-4-python\n",
      "https://regex101.com/\n",
      "https://twitter.com/regexdrill\n",
      "​\n",
      "​\n",
      "​\n",
      "​\n",
      "https://regex101.com/\n",
      "http://webscraper.io/test-sites/e-commerce/allinone/phones\n",
      "https://www.reebok.com/us/flexagon-energy-shoes---preschool/DV8354.html\n",
      "​\n",
      "PreviousModule 8 – Data Types & RegEx\n",
      "NextModule 10 – Working with APIs\n",
      "Web Scraping\n",
      "Linux\n",
      "Windows\n",
      "Regular Expressions\n",
      "Lab 8\n",
      "GitHub\n"
     ]
    }
   ],
   "source": [
    "soup = getSoup('https://it3038c.github.io/IT3038C/modules/9')\n",
    "elements = getTextByElement(soup, 'h1', {})\n",
    "for element in elements:\n",
    "    print(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Link: https://analytics.usa.gov\n",
      "Branches points from here: 17\n",
      "Current Link: https://github.com/GSA/analytics.usa.gov\n",
      "Branches points from here: 74\n",
      "Current Link: https://cli.github.com\n",
      "Branches points from here: 40\n",
      "Current Link: https://www.facebook.com/GitHub\n",
      "\n",
      "Link chain ended\n",
      "Total links visited: 4\n",
      "Links visited: {'https://cli.github.com', 'https://www.facebook.com/GitHub', 'https://analytics.usa.gov', 'https://github.com/GSA/analytics.usa.gov'}\n"
     ]
    }
   ],
   "source": [
    "testURL = 'https://analytics.usa.gov'\n",
    "traverseWeb(testURL, set())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
